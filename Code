#Code

################# TO DO LIST

set.seed(123)
library(readxl)
library(xts)
library(data.table)
library(dplyr)
library(MCS)
library(tidyr)
library(parallel)



# Vector of tickers to process
tickers <- c(
             # "BBDC4"
             # ,
             # "CSNA3"
             # ,
             "GGBR4"
             ,
             "IBOV_BS"
             ,
             "ITUB4"
             ,
             "BOVA11"
             ,
             "PETR4"
             )

forecast_horizon <-c(
                     # "daily"
                     # ,
                     # "lead_5"
                     # ,
                     # "lead_10"
                     # ,
                     "lead_21"
                     )

# Base path up to each ticker’s folder
base_dir <- "~/FEA_USP/Mestrado/Novos/Tese/R/Correto_sqrt_ln/HAR_and_HIV_BASE_NOVA_HARQ/Impurity"


for (h in forecast_horizon) {
  
  # Determine k based on h
  k <- switch(h,
              "daily" = 1,
              "lead_5" = 5,
              "lead_10" = 10,
              "lead_21" = 21)
  
  for (tkr in tickers) {  # Move ticker loop inside h loop
    in_file <- file.path(base_dir, tkr, "RData_TR", paste0("MCS_", tkr, "_", h, ".RData"))
    # Rest of the code per ticker and h
    
    if (!file.exists(in_file)) {
      warning("File not found, skipping: ", in_file); next
    }
    loaded_names <- load(in_file)
    message("Loaded: ", basename(in_file))
    
    # Remove objects containing "MCS" from the global environment
    rm(list = grep("MCS", ls(), value = TRUE), envir = .GlobalEnv)
    
    
    # test_rv_var <- get(paste0("test_RV_", h))
    # ln_test_rv_var <- get(paste0("ln_test_RV_", h))
    # sqrt_test_rv_var <- get(paste0("sqrt_test_RV_", h))
    start_time <-Sys.time()
        ############# Importance em level #####################################################
    # Extract percentage_importance for all models
    percentage_importance_list <- lapply(results_rf, function(x) x$percentage_importance)
    
    # Ensure the list retains model names (inherited from results_rf)
    names(percentage_importance_list) <- names(results_rf)
    
    # Define the variables to sum for each model
    target_vars <- c(
      "RV_lag1", "RV_lag5", "RV_lag21",
      "C_lag1", "C_lag5", "C_lag21",
      "J_lag1", "J_lag5", "J_lag21", 
      "L_lag1", "L_lag5", "L_lag21",
      "RVQ_lag1", "JN_lag1", "JP_lag1", "BV_lag1"
    )
    
    # Calculate total percentage for target variables in each model
    model_importance <- lapply(percentage_importance_list, function(x) {
      sum(x[names(x) %in% target_vars], na.rm = TRUE)
    })
    
    # Keep the same model names structure
    names(model_importance) <- names(percentage_importance_list)
    
    # Sum IVAR for each model
    IV_importance <- sapply(percentage_importance_list, function(x) {
      sum(x[c("IVAR_1","IVAR_5","IVAR_21")], na.rm = TRUE)
    })
    
    # Convert model_importance from list to numeric vector (same structure as IV_importance)
    model_importance <- unlist(model_importance)
    
    # Create a data frame with model names, model_importance, IV_importance, and their difference
    importance_comparison <- data.frame(
      Model_Importance = round(model_importance, digits = 1),
      IV_Importance = round(IV_importance, digits = 1),
      Topics = round(100 - model_importance - IV_importance, digits=1)
    )
    
    # Print the result
    print(importance_comparison)
############ MCS  ################

cl <- makeCluster(5)
realized_variable <- test_rv_var

predictions <- all_results$level$predictions

na_columns <- colnames(predictions)[colSums(is.na(log(predictions))) > 0]
clean_predictions <- predictions[, !(colnames(log(predictions)) %in% na_columns)]


clean_predictions <- clean_predictions[, !grepl("HARQ|lasso|^IV|regressores_HAR_ols|topics_ols|topics_IV_ols|regressores_HAR_wls|topics_wls|topics_IV_wls", colnames(clean_predictions))]

QLIKE <-  log(clean_predictions) +
  (as.numeric(realized_variable) / clean_predictions)



AE <- abs(sweep(clean_predictions, 1, as.numeric(realized_variable), "-"))
SE <- (sweep(clean_predictions, 1, as.numeric(realized_variable), "-"))^2
PAE <- 100 * abs(sweep(clean_predictions, 1, as.numeric(realized_variable), "-"))/ as.numeric(realized_variable)
HSE <- 100 * (sweep(clean_predictions, 1, as.numeric(realized_variable), "-")/ as.numeric(realized_variable))^2





stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_QLIKE <- MCSprocedure(cbind(QLIKE),
                          alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_SE <- MCSprocedure(cbind(SE),
                       alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_AE <- MCSprocedure(cbind(AE),
                       alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_PAE <- MCSprocedure(cbind(PAE),
                        alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_HSE <- MCSprocedure(cbind(HSE),
                        alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)



# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()




########### MCS regressores ################


cl <- makeCluster(5)
realized_variable <- test_rv_var

clean_predictions <- predictions[, !(colnames(log(predictions)) %in% na_columns)]
clean_predictions_regressores_HAR <- clean_predictions[, !grepl("HARQ|topics|IV|regressores_HAR_ols|regressores_HAR_wls", colnames(clean_predictions))]


QLIKE_regressores_HAR <-  log(clean_predictions_regressores_HAR) +
  (as.numeric(realized_variable) / clean_predictions_regressores_HAR)


AE_regressores_HAR <- abs(sweep(clean_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-"))
SE_regressores_HAR <- (sweep(clean_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-"))^2
PAE_regressores_HAR <- 100 * abs(sweep(clean_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-"))/ as.numeric(realized_variable)
HSE_regressores_HAR <- 100 * (sweep(clean_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-")/ as.numeric(realized_variable))^2

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_QLIKE_regressores_HAR <- MCSprocedure(cbind(QLIKE_regressores_HAR),
                               alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_SE_regressores_HAR <- MCSprocedure(cbind(SE_regressores_HAR),
                            alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_AE_regressores_HAR <- MCSprocedure(cbind(AE_regressores_HAR),
                            alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_PAE_regressores_HAR <- MCSprocedure(cbind(PAE_regressores_HAR),
                             alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)


MCS_HSE_regressores_HAR <- MCSprocedure(cbind(HSE_regressores_HAR),
                             alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)



# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)



############ MCS topics_IV ################


cl <- makeCluster(5)
realized_variable <- test_rv_var

clean_predictions <- predictions[, !(colnames(log(predictions)) %in% na_columns)]
clean_predictions_TopicsIV <- clean_predictions[
  ,
  !grepl("^HARQ|^IV|regressores_HAR|topics_IV_ols|topics_IV_wls", colnames(clean_predictions)) &
    # If it's a topics column, it must start with topics_IV
    (!grepl("topics", colnames(clean_predictions)) | grepl("^topics_IV", colnames(clean_predictions)))
]


QLIKE_TopicsIV <-  log(clean_predictions_TopicsIV) +
  (as.numeric(realized_variable) / clean_predictions_TopicsIV)


AE_TopicsIV <- abs(sweep(clean_predictions_TopicsIV, 1, as.numeric(realized_variable), "-"))
SE_TopicsIV <- (sweep(clean_predictions_TopicsIV, 1, as.numeric(realized_variable), "-"))^2
PAE_TopicsIV <- 100 * abs(sweep(clean_predictions_TopicsIV, 1, as.numeric(realized_variable), "-"))/ as.numeric(realized_variable)
HSE_TopicsIV <- 100 * (sweep(clean_predictions_TopicsIV, 1, as.numeric(realized_variable), "-")/ as.numeric(realized_variable))^2

gc()
MCS_QLIKE_TopicsIV <- MCSprocedure(cbind(QLIKE_TopicsIV),
                                   alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_SE_TopicsIV <- MCSprocedure(cbind(SE_TopicsIV),
                                alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_AE_TopicsIV <- MCSprocedure(cbind(AE_TopicsIV),
                                alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_PAE_TopicsIV <- MCSprocedure(cbind(PAE_TopicsIV),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_HSE_TopicsIV <- MCSprocedure(cbind(HSE_TopicsIV),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)



# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()




#
############ MCS topics ################

cl <- makeCluster(5)

realized_variable <- test_rv_var

clean_predictions <- predictions[, !(colnames(log(predictions)) %in% na_columns)]
clean_predictions_Topics <- clean_predictions[, !grepl("HARQ|regressores_HAR|IV|topics_wls|topics_ols", colnames(clean_predictions))]


QLIKE_Topics <- log(clean_predictions_Topics) +
  (as.numeric(realized_variable) / clean_predictions_Topics)


AE_Topics <- abs(sweep(clean_predictions_Topics, 1, as.numeric(realized_variable), "-"))
SE_Topics <- (sweep(clean_predictions_Topics, 1, as.numeric(realized_variable), "-"))^2
PAE_Topics <- 100 * abs(sweep(clean_predictions_Topics, 1, as.numeric(realized_variable), "-"))/ as.numeric(realized_variable)
HSE_Topics <- 100 * (sweep(clean_predictions_Topics, 1, as.numeric(realized_variable), "-")/ as.numeric(realized_variable))^2


gc()
MCS_QLIKE_Topics <- MCSprocedure(cbind(QLIKE_Topics),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_SE_Topics <- MCSprocedure(cbind(SE_Topics),
                              alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_AE_Topics <- MCSprocedure(cbind(AE_Topics),
                              alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_PAE_Topics <- MCSprocedure(cbind(PAE_Topics),
                               alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_HSE_Topics <- MCSprocedure(cbind(HSE_Topics),
                               alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()





############ MCS IV ################

cl <- makeCluster(5)

realized_variable <- test_rv_var

clean_predictions <- predictions[, !(colnames(log(predictions)) %in% na_columns)]
clean_predictions_IV <- clean_predictions[, !grepl("HARQ|regressores_HAR|topics", colnames(clean_predictions))]


QLIKE_IV <- log(clean_predictions_IV) +
  (as.numeric(realized_variable) / clean_predictions_IV)


AE_IV <- abs(sweep(clean_predictions_IV, 1, as.numeric(realized_variable), "-"))
SE_IV <- (sweep(clean_predictions_IV, 1, as.numeric(realized_variable), "-"))^2
PAE_IV <- 100 * abs(sweep(clean_predictions_IV, 1, as.numeric(realized_variable), "-"))/ as.numeric(realized_variable)
HSE_IV <- 100 * (sweep(clean_predictions_IV, 1, as.numeric(realized_variable), "-")/ as.numeric(realized_variable))^2


gc()
MCS_QLIKE_IV <- MCSprocedure(cbind(QLIKE_IV),
                             alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_SE_IV <- MCSprocedure(cbind(SE_IV),
                          alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_AE_IV <- MCSprocedure(cbind(AE_IV),
                          alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_PAE_IV <- MCSprocedure(cbind(PAE_IV),
                           alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
MCS_HSE_IV <- MCSprocedure(cbind(HSE_IV),
                           alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)



# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()





        ############# Importance em ln #####################################################
# Extract percentage_importance for all models
ln_percentage_importance_list <- lapply(ln_results_rf, function(x) x$percentage_importance)

# Ensure the list retains model names (inherited from results_rf)
names(ln_percentage_importance_list) <- names(ln_results_rf)

# Define the variables to sum for each model
target_vars <- c(
  "RV_lag1", "RV_lag5", "RV_lag21",
  "C_lag1", "C_lag5", "C_lag21",
  "J_lag1", "J_lag5", "J_lag21", 
  "L_lag1", "L_lag5", "L_lag21",
  "RVQ_lag1", "JN_lag1", "JP_lag1", "BV_lag1"
)

# Calculate total percentage for target variables in each model
ln_model_importance <- lapply(ln_percentage_importance_list, function(x) {
  sum(x[names(x) %in% target_vars], na.rm = TRUE)
})

# Keep the same model names structure
names(ln_model_importance) <- names(ln_percentage_importance_list)

# Sum IVAR for each model
ln_IV_importance <- sapply(ln_percentage_importance_list, function(x) {
  sum(x[c("IVAR_1","IVAR_5","IVAR_21")], na.rm = TRUE)
})

# Convert model_importance from list to numeric vector (same structure as IV_importance)
ln_model_importance <- unlist(ln_model_importance)

# Create a data frame with model names, model_importance, IV_importance, and their difference
ln_importance_comparison <- data.frame(
  Model_Importance = round(ln_model_importance, digits = 1),
  IV_Importance = round(ln_IV_importance, digits = 1),
  Topics = round(100 - model_importance - IV_importance, digits=1)
)

# Print the result
print(ln_importance_comparison)
############ ln_MCS ################

cl <- makeCluster(5)

realized_variable <- ln_test_rv_var

ln_predictions <- all_results$ln$predictions
ln_predictions <- ln_predictions[, !grepl("HARQ|regressores_HAR_ols|regressores_HAR_wls|ln_IV|topics_wls|topics_ols", colnames(ln_predictions))]


ln_AE <- abs(sweep(ln_predictions, 1, as.numeric(realized_variable), "-"))
ln_SE <- (sweep(ln_predictions, 1, as.numeric(realized_variable), "-"))^2


gc()
ln_MCS_SE <- MCSprocedure(cbind(ln_SE),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
ln_MCS_AE <- MCSprocedure(cbind(ln_AE),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()




############ ln_MCS regressores ################

cl <- makeCluster(5)

realized_variable <- ln_test_rv_var

ln_predictions <- all_results$ln$predictions
ln_predictions_regressores_HAR <- ln_predictions[, !grepl("HARQ|topics|IV|regressores_HAR_wls|regressores_HAR_ols", colnames(ln_predictions))]


ln_AE_regressores_HAR <- abs(sweep(ln_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-"))
ln_SE_regressores_HAR <- (sweep(ln_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-"))^2


gc()
ln_MCS_SE_regressores_HAR <- MCSprocedure(cbind(ln_SE_regressores_HAR),
                               alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
ln_MCS_AE_regressores_HAR <- MCSprocedure(cbind(ln_AE_regressores_HAR),
                               alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()




############ ln_MCS topics_IV ################

cl <- makeCluster(5)

realized_variable <- ln_test_rv_var

ln_predictions <- all_results$ln$predictions
ln_predictions_TopicsIV <- ln_predictions[
  ,
  !grepl("^HARQ|ln_IV|regressores_HAR|topics_IV_wls|topics_IV_ols", colnames(ln_predictions)) &
    # If it's a topics column, keep only those starting with ln_topics_IV
    (!grepl("topics", colnames(ln_predictions)) | grepl("^ln_topics_IV", colnames(ln_predictions)))
]



ln_AE_TopicsIV <- abs(sweep(ln_predictions_TopicsIV, 1, as.numeric(realized_variable), "-"))
ln_SE_TopicsIV <- (sweep(ln_predictions_TopicsIV, 1, as.numeric(realized_variable), "-"))^2


gc()
ln_MCS_SE_TopicsIV <- MCSprocedure(cbind(ln_SE_TopicsIV), 
                                   alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
ln_MCS_AE_TopicsIV <- MCSprocedure(cbind(ln_AE_TopicsIV), 
                                   alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()




############ ln_MCS topics ################

cl <- makeCluster(5)

realized_variable <- ln_test_rv_var

ln_predictions <- all_results$ln$predictions
ln_predictions_Topics <- ln_predictions[, !grepl("HARQ|regressores_HAR|IV|topics_wls|topics_ols", colnames(ln_predictions))]


ln_AE_Topics <- abs(sweep(ln_predictions_Topics, 1, as.numeric(realized_variable), "-"))
ln_SE_Topics <- (sweep(ln_predictions_Topics, 1, as.numeric(realized_variable), "-"))^2


gc()
ln_MCS_SE_Topics <- MCSprocedure(cbind(ln_SE_Topics),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
ln_MCS_AE_Topics <- MCSprocedure(cbind(ln_AE_Topics),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()




############ ln_MCS IV ################

cl <- makeCluster(5)

realized_variable <- ln_test_rv_var

ln_predictions <- all_results$ln$predictions
ln_predictions_IV <- ln_predictions[, !grepl("HARQ|regressores_HAR|topics", colnames(ln_predictions))]


ln_AE_IV <- abs(sweep(ln_predictions_IV, 1, as.numeric(realized_variable), "-"))
ln_SE_IV <- (sweep(ln_predictions_IV, 1, as.numeric(realized_variable), "-"))^2


gc()
ln_MCS_SE_IV <- MCSprocedure(cbind(ln_SE_IV),
                             alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
ln_MCS_AE_IV <- MCSprocedure(cbind(ln_AE_IV),
                             alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()


  
        ############# Importance em sqrt #####################################################
# Extract percentage_importance for all models
sqrt_percentage_importance_list <- lapply(sqrt_results_rf, function(x) x$percentage_importance)

# Ensure the list retains model names (inherited from results_rf)
names(sqrt_percentage_importance_list) <- names(sqrt_results_rf)

# Define the variables to sum for each model
target_vars <- c(
  "RV_lag1", "RV_lag5", "RV_lag21",
  "C_lag1", "C_lag5", "C_lag21",
  "J_lag1", "J_lag5", "J_lag21", 
  "L_lag1", "L_lag5", "L_lag21",
  "RVQ_lag1", "JN_lag1", "JP_lag1", "BV_lag1"
)

# Calculate total percentage for target variables in each model
sqrt_model_importance <- lapply(sqrt_percentage_importance_list, function(x) {
  sum(x[names(x) %in% target_vars], na.rm = TRUE)
})

# Keep the same model names structure
names(sqrt_model_importance) <- names(sqrt_percentage_importance_list)

# Sum IVAR for each model
sqrt_IV_importance <- sapply(sqrt_percentage_importance_list, function(x) {
  sum(x[c("IVAR_1", "IVAR_5", "IVAR_21")], na.rm = TRUE)
})

# Convert model_importance from list to numeric vector (same structure as IV_importance)
sqrt_model_importance <- unlist(sqrt_model_importance)

# Create a data frame with model names, model_importance, IV_importance, and their difference
sqrt_importance_comparison <- data.frame(
  Model_Importance = round(sqrt_model_importance, digits = 1),
  IV_Importance    = round(sqrt_IV_importance, digits = 1),
  Topics           = round(100 - sqrt_model_importance - sqrt_IV_importance, digits = 1)
)

# Print the result
print(sqrt_importance_comparison)

############ sqrt_MCS #############

cl <- makeCluster(5)

sqrt_predictions <- all_results$sqrt$predictions
sqrt_predictions <- sqrt_predictions[, !grepl("HARQ|^sqrt_IV|topics_ols|topics_IV_ols|topics_wls|topics_IV_wls|regressores_HAR_wls|regressores_HAR_ols", colnames(sqrt_predictions))]


realized_variable <- sqrt_test_rv_var

sqrt_SE <- (sweep(sqrt_predictions, 1, as.numeric(realized_variable), "-"))^2
sqrt_AE <- abs(sweep(sqrt_predictions, 1, as.numeric(realized_variable), "-"))





gc()
sqrt_MCS_SE <- MCSprocedure(cbind(sqrt_SE), alpha=0.1, B=10000, cl=cl, statistic="TR", k=k, verbose=TRUE)
stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
sqrt_MCS_AE <- MCSprocedure(cbind(sqrt_AE), alpha=0.1, B=10000, cl=cl, statistic="TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()

########### sqrt_MCS regressores_HAR ################

cl <- makeCluster(5)

realized_variable <- sqrt_test_rv_var

sqrt_predictions <- all_results$sqrt$predictions
sqrt_predictions_regressores_HAR <- sqrt_predictions[, !grepl("HARQ|topics|IV|regressores_HAR_wls|regressores_HAR_ols", colnames(sqrt_predictions))]


sqrt_AE_regressores_HAR <- abs(sweep(sqrt_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-"))
sqrt_SE_regressores_HAR <- (sweep(sqrt_predictions_regressores_HAR, 1, as.numeric(realized_variable), "-"))^2


gc()
sqrt_MCS_SE_regressores_HAR <- MCSprocedure(cbind(sqrt_SE_regressores_HAR),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
sqrt_MCS_AE_regressores_HAR <- MCSprocedure(cbind(sqrt_AE_regressores_HAR),
                                 alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()




############ sqrt_MCS topics_IV ################

cl <- makeCluster(5)

realized_variable <- sqrt_test_rv_var

sqrt_predictions <- all_results$sqrt$predictions
sqrt_predictions_TopicsIV <- sqrt_predictions[
  ,
  !grepl("HARQ|sqrt_IV|regressores_HAR|topics_IV_wls|topics_IV_ols", colnames(sqrt_predictions)) &
    # Keep all non-topic cols, but for topics only those starting with sqrt_topics_IV
    (!grepl("topics", colnames(sqrt_predictions)) | grepl("^sqrt_topics_IV", colnames(sqrt_predictions)))
]



sqrt_AE_TopicsIV <- abs(sweep(sqrt_predictions_TopicsIV, 1, as.numeric(realized_variable), "-"))
sqrt_SE_TopicsIV <- (sweep(sqrt_predictions_TopicsIV, 1, as.numeric(realized_variable), "-"))^2


gc()
sqrt_MCS_SE_TopicsIV <- MCSprocedure(cbind(sqrt_SE_TopicsIV), 
                                     alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
sqrt_MCS_AE_TopicsIV <- MCSprocedure(cbind(sqrt_AE_TopicsIV), 
                                     alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()



########### sqrt_MCS topics ################

cl <- makeCluster(5)

realized_variable <- sqrt_test_rv_var

sqrt_predictions <- all_results$sqrt$predictions
sqrt_predictions_Topics <- sqrt_predictions[, !grepl("HARQ|regressores_HAR|IV|topics_wls|topics_ols", colnames(sqrt_predictions))]


sqrt_AE_Topics <- abs(sweep(sqrt_predictions_Topics, 1, as.numeric(realized_variable), "-"))
sqrt_SE_Topics <- (sweep(sqrt_predictions_Topics, 1, as.numeric(realized_variable), "-"))^2


gc()
sqrt_MCS_SE_Topics <- MCSprocedure(cbind(sqrt_SE_Topics),
                                   alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)


stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
sqrt_MCS_AE_Topics <- MCSprocedure(cbind(sqrt_AE_Topics),
                                   alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()



########### sqrt_MCS IV ################

cl <- makeCluster(5)

realized_variable <- sqrt_test_rv_var

sqrt_predictions <- all_results$sqrt$predictions
sqrt_predictions_IV <- sqrt_predictions[, !grepl("HARQ|regressores_HAR|topics", colnames(sqrt_predictions))]


sqrt_AE_IV <- abs(sweep(sqrt_predictions_IV, 1, as.numeric(realized_variable), "-"))
sqrt_SE_IV <- (sweep(sqrt_predictions_IV, 1, as.numeric(realized_variable), "-"))^2


gc()
sqrt_MCS_SE_IV <- MCSprocedure(cbind(sqrt_SE_IV),
                               alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

stopCluster(cl)
rm(cl)
gc()
cl <- makeCluster(5)
sqrt_MCS_AE_IV <- MCSprocedure(cbind(sqrt_AE_IV),
                               alpha = 0.1, B = 10000, cl = cl, statistic = "TR", k=k, verbose=TRUE)

# Cleanup parallel cluster
stopCluster(cl)
rm(cl)
gc()


############### salvar novos arquivos\############

end_time <-Sys.time()
print(end_time - start_time)

objs <- setdiff(ls(envir = globalenv()), c("base_dir", "forecast_horizon", "tickers",
                                           "tkr", "h","k",
                                           # "test_rv_var","ln_test_rv_var","sqrt_test_rv_var",
                                           "start_time","end_time","cl"))


out_file <- file.path(base_dir, tkr, "RData_TR", paste0("MCS_", tkr, "_", h, ".RData"))
# Save objects from loop_env
save(
  list = objs,
  file = out_file
)
message("Saved objects to: ", basename(out_file))

# Remove the actual objects from loop_env (if needed)
rm(list = objs)
gc(full = TRUE, verbose = FALSE)



  }
}
  
################# TO DO LIST

set.seed(123)
library(highfrequency)
library(readxl)
library(xts)
library(data.table)
library(glmnet)
library(zoo)
library(HDeconometrics)
library(dplyr)
library(foreach)
library(doParallel)
library(MCS)
library(forecast)
library(ranger)
library(tidyr)
library(ggplot2)

# Vector of tickers to process
tickers <- c(
  "BBDC4", "CSNA3","GGBR4"
  ,"IBOV_BS"
  ,"ITUB4",
  "BOVA11", "PETR4")

forecast_horizon <-c(
  # "daily",
  # "lead_5"
  # , 
  "lead_10",
  "lead_21"
  )

# Base path up to each ticker’s folder
base_dir <- "~/FEA_USP/Mestrado/Novos/Tese/R/Correto_sqrt_ln/HAR_and_HIV_BASE_NOVA_HARQ/Impurity"

############# Function for regularização  #########################################



#Optionally, wrap the inner loop in a function and compile it
runRollingWindow <- function(model_data,
                             train_size,
                             time_index,
                             n_obs) {
  predictions_ols <- xts(rep(NA, n_obs - train_size), order.by = time_index)
  predictions_wls     <- predictions_ols
  # predictions_lasso   <- predictions_o ols
  # predictions_ridge   <- predictions_ols
  # predictions_adalasso<- predictions_ols
  
  
  # nonzero_coefs_lasso    <- vector("list", length = n_obs - train_size)
  # nonzero_coefs_adalasso <- vector("list", length = n_obs - train_size)
  
  for (i in train_size:(n_obs-1)) {
    
    # Extract and scale training data
    X_train_raw <- as.matrix(model_data[(i - train_size + 1):i, ])
    y_train <- as.matrix(target_variable[(i - train_size + 1):i])
    
    # Calculate scaling parameters
    # meanain <- colMeans(X_train_raw)
    # sdain <- apply(X_train_raw, 2, sd)
    
    # Scale features
    # Xain <- scale(X_train_raw, center = meanain, scale = sdain)
    train_df <- data.frame(y = y_train, X_train_raw)
    
    # Prepare test data
    X_test_raw <- model_data[i + 1, , drop = FALSE]
    # X_test <- scale(X_test_raw, center = meanain, scale = sdain)
    
    # OLS
    fit_ols <- lm(rv_var ~ ., data = train_df)
    predictions_ols[i - train_size + 1] <- predict(fit_ols, newdata = X_test_raw)
    
    # WLS
    weights <- 1 / (abs(fitted(fit_ols)))
    fit_wls <- lm(rv_var ~ ., data = train_df, weights = weights)
    predictions_wls[i - train_size + 1] <- predict(fit_wls, newdata = X_test_raw)
    
    X_test <- as.matrix(X_test_raw)
    
    # Ridge
    # fit_ridge <- ic.glmnet(Xain,
    #                        y_train,
    #                        alpha = 0,
    #                        crit = "bic",
    #                        standardize = FALSE)
    # predictions_ridge[i - train_size + 1] <- predict(fit_ridge, newdata = X_test)
    
    # Lasso
    # fit_lasso <- ic.glmnet(Xain,
    #                        y_train,
    #                        alpha = 1,
    #                        crit = "bic",
    #                        standardize = FALSE)
    # coef_lasso <- as.matrix(coef(fit_lasso))
    # nonzero_indices_lasso <- which(coef_lasso != 0)
    # nonzero_coefs_lasso[[i - train_size + 1]] <- rownames(coef_lasso)[nonzero_indices_lasso]
    # predictions_lasso[i - train_size + 1] <- predict(fit_lasso, newdata = X_test)
    
    
    # Adaptive Lasso: use Ridge coefficients to build penalty factor
    # first_step_coef <- coef(fit_ols)[-1]
    # penalty_factor <- abs(first_step_coef)^(-1)
    # adalasso <- ic.glmnet(Xain,
    #                       y_train,
    #                       crit = "bic",
    #                       penalty.factor = penalty_factor,
    #                       standardize = FALSE)
    # coef_adalasso <- as.matrix(coef(adalasso))
    # nonzero_indices_adalasso <- which(coef_adalasso != 0)
    # nonzero_coefs_adalasso[[i - train_size + 1]] <- rownames(coef_adalasso)[nonzero_indices_adalasso]
    # predictions_adalasso[i - train_size + 1] <- predict(adalasso, newdata = X_test)
    
    
    # Cleanup to prevent memory bloat
    rm(X_train,
       y_train,
       # fit_ridge,
       # fit_lasso,
       # adalasso,
       fit_ols,
       fit_wls
    )
    if (i %% 10 == 0) gc(full = TRUE, verbose = FALSE)  # Lightweight garbage collectionarbage collection
  }
  
  
  list(
    predictions_ols      = predictions_ols,
    # predictions_ridge    = predictions_ridge,
    # predictions_lasso    = predictions_lasso,
    # predictions_adalasso = predictions_adalasso,
    # nonzero_coefs_lasso      = nonzero_coefs_lasso,
    # nonzero_coefs_adalasso   = nonzero_coefs_adalasso,
    predictions_wls      = predictions_wls
    
  )
}







############# Function for Random Forest #########################
# Define the rolling window function
runRollingWindow_rf <- function(model_data,
                                train_size,
                                time_index,
                                n_obs,
                                always_split_vars = NULL) {  # Added parameter
  
  # Initialize predictions and importance storage
  n_predictions <- n_obs - train_size
  predictions_rf <- xts(rep(NA, n_predictions), order.by = time_index)
  importance_list <- list()
  
  # Combine data into a matrix
  full_data <- data.frame(target_variable, model_data)
  full_matrix <- as.matrix(full_data)
  
  # Loop through rolling windows
  for (i in train_size:(n_obs - 1)) {
    idx <- i - train_size + 1
    
    # Training data
    train_idx <- idx:i
    X_train_raw <- full_matrix[train_idx, -1, drop = FALSE]
    y_train <- full_matrix[train_idx, 1, drop = FALSE]
    X_test_raw <- full_matrix[i + 1, -1, drop = FALSE]
    
    # Create Bagging model (mtry = number of predictors)
    fit_rf <- ranger(
      x = X_train_raw, 
      y = y_train,
      num.trees = 1000,
      # mtry = ncol(X_train_raw),  # Key change: use all features for each split
      num.threads = 20,
      seed = 123,
      importance = "impurity",
      always.split.variables = always_split_vars
    )
    
    # Store predictions and importance
    predictions_rf[idx] <- predict(fit_rf, data = X_test_raw)$predictions
    importance_list[[idx]] <- fit_rf$variable.importance
    
    # Cleanup
    rm(fit_rf)
    if (i %% 10 == 0) gc(verbose = FALSE, full = TRUE)
  }
  
  # Calculate importance metrics
  importance_df <- do.call(rbind, importance_list)
  mean_importance <- colMeans(importance_df, na.rm = TRUE)
  total_importance <- sum(mean_importance, na.rm = TRUE)
  mean_importance_perc <- round((mean_importance / total_importance) * 100, 2)
  
  # Return results
  list(
    predictions_rf = predictions_rf,
    raw_importance = mean_importance,
    percentage_importance = mean_importance_perc
  )
}




################### LOOP throught all the tickers daily ####################

for (horizon in forecast_horizon) {
  for (tkr in tickers) { 
    # Create a new environment for this iteration
    setwd(paste0("~/FEA_USP/Mestrado/Novos/Tese/R/Normal/", tkr, "/Bases_RDS_IV_loop"))
    
  
    start_time <-Sys.time()
    
    assign(paste0("RV_", horizon), readRDS(paste0("RV_", horizon, ".rds")))
    assign(paste0("ln_RV_", horizon), readRDS(paste0("ln_RV_", horizon, ".rds")))
    assign(paste0("sqrt_RV_", horizon), readRDS(paste0("sqrt_RV_", horizon, ".rds")))
    
    HAR <- readRDS("HAR.rds")
    regressores_HAR <- readRDS("regressores_HAR.rds")
    regressores_HAR <- regressores_HAR[index(get(paste0("RV_", horizon)))]
    
    topics <- subset(regressores_HAR, select = -c(
      RV_lag1, RV_lag5, RV_lag21, IVAR_1, IVAR_5, IVAR_21
    ))
    
    topics_IV <- subset(regressores_HAR, select = -c(
      RV_lag1, RV_lag5, RV_lag21
    ))
    
    IV <- subset(regressores_HAR, select = c(
      IVAR_1, IVAR_5, IVAR_21
    ))
    
    regressores_HAR <- subset(regressores_HAR, select = -c(
      IVAR_1, IVAR_5, IVAR_21
    ))
    
    HARCJ <- readRDS("HARCJ.rds")
    LHARCJ <- readRDS("LHARCJ.rds")
    HARQ_1 <- readRDS("HARQ_1.rds")
    SHAR <- readRDS("SHAR.rds")
    
    ln_HAR <- readRDS("ln_HAR.rds")
    ln_regressores_HAR <- readRDS("ln_regressores_HAR.rds")
    ln_regressores_HAR <- ln_regressores_HAR[index(get(paste0("ln_RV_", horizon)))]
    
    ln_topics <- subset(ln_regressores_HAR, select = -c(
      RV_lag1, RV_lag5, RV_lag21, IVAR_1, IVAR_5, IVAR_21
    ))
    
    ln_topics_IV <- subset(ln_regressores_HAR, select = -c(
      RV_lag1, RV_lag5, RV_lag21
    ))
    
    ln_IV <- subset(ln_regressores_HAR, select = c(
      IVAR_1, IVAR_5, IVAR_21
    ))
    
    ln_regressores_HAR <- subset(ln_regressores_HAR, select = -c(
      IVAR_1, IVAR_5, IVAR_21
    ))
    
    ln_HARCJ <- readRDS("ln_HARCJ.rds")
    ln_LHARCJ <- readRDS("ln_LHARCJ.rds")
    ln_HARQ_1 <- readRDS("ln_HARQ_1.rds")
    ln_SHAR <- readRDS("ln_SHAR.rds")
    
    sqrt_HAR <- readRDS("sqrt_HAR.rds")
    sqrt_regressores_HAR <- readRDS("sqrt_regressores_HAR.rds")
    sqrt_regressores_HAR <- sqrt_regressores_HAR[index(get(paste0("sqrt_RV_", horizon)))]
    
    sqrt_topics <- subset(sqrt_regressores_HAR, select = -c(
      RV_lag1, RV_lag5, RV_lag21, IVAR_1, IVAR_5, IVAR_21
    ))
    
    sqrt_topics_IV <- subset(sqrt_regressores_HAR, select = -c(
      RV_lag1, RV_lag5, RV_lag21
    ))
    
    sqrt_IV <- subset(sqrt_regressores_HAR, select = c(
      IVAR_1, IVAR_5, IVAR_21
    ))
    
    sqrt_regressores_HAR <- subset(sqrt_regressores_HAR, select = -c(
      IVAR_1, IVAR_5, IVAR_21
    ))
    
    sqrt_HARCJ <- readRDS("sqrt_HARCJ.rds")
    sqrt_LHARCJ <- readRDS("sqrt_LHARCJ.rds")
    sqrt_HARQ_1 <- readRDS("sqrt_HARQ_1.rds")
    sqrt_SHAR <- readRDS("sqrt_SHAR.rds")
    
    
    
    
    # Access objects through loop_env
    rv_var <- get(paste0("RV_", horizon))
    ln_rv_var <- get(paste0("ln_RV_", horizon))
    sqrt_rv_var <- get(paste0("sqrt_RV_", horizon))
    
    
      ############# Carregar bases RV #############
      
      
      level <- list(
        # Regressores first
        # regressores_HAR = regressores_HAR,
        # topics = topics,
        # topics_IV = topics_IV,
        IV = IV,
        
        # Remaining variables
        HAR = HAR,
        HARCJ = HARCJ,
        LHARCJ = LHARCJ,
        HARQ_1 = HARQ_1,
        SHAR = SHAR
      )
      
      
      
      
      train_size <- sum(index(rv_var) <= as.POSIXct("2020-12-31 23:59", format="%Y-%m-%d %H:%M"))
      
      train_rv_var = rv_var[1:train_size, ]
      test_rv_var <- rv_var[(train_size + 1):nrow(rv_var), ] 
      
      gc()
      
      target_variable <- rv_var
      # 2a. If you know which column you want to rename (e.g. the first column):
      colnames(target_variable)[1] <- "rv_var"
      realized_variable <- test_rv_var
      
      # Precompute constant values outside the parallel loop
      n_obs <- nrow(target_variable)
      time_index <- index(target_variable[(train_size + 1):n_obs])
      
      ############# Regularização em level ############################
      results <- list()
      for(model_name in names(level)) {
        model_data <- level[[model_name]]
        out <- runRollingWindow(
          model_data = model_data,
          train_size = train_size,
          time_index = time_index,
          n_obs = n_obs
        )
        results[[model_name]] <- out
      }
      
      nonzero_coefs_lasso_results    <- do.call(cbind, lapply(results, `[[`, "nonzero_coefs_lasso"))
      nonzero_coefs_adalasso_results <- do.call(cbind, lapply(results, `[[`, "nonzero_coefs_adalasso"))
      gc()
      
      
      
      ############# Random Forest em level ##################
      level <- list(
        # Regressores first
        regressores_HAR = regressores_HAR,
        topics = topics,
        topics_IV = topics_IV,
        IV = IV,
        
        # Remaining variables
        HAR = HAR,
        HARCJ = HARCJ,
        LHARCJ = LHARCJ,
        HARQ_1 = HARQ_1,
        SHAR = SHAR
      )
      
      # Initialize results list
      results_rf <- list()
      
      # Main sequential execution
      for (model_name in names(level)) {
        model_data <- level[[model_name]]
        
        # Determine always.split.variables
        if (grepl("_IV$", model_name)) {
          always_vars <- c("IVAR_1", "IVAR_5", "IVAR_21")
        } else {
          model_suffixes <- c("HAR", "HARCJ", "LHARCJ", "HARQ_1", "SHAR")
          pattern <- paste0("_(", paste(model_suffixes, collapse = "|"), ")$")
          
          if (grepl(pattern, model_name)) {
            base_model <- regmatches(model_name, regexpr(pattern, model_name))
            base_model <- gsub("_", "", base_model)
            always_vars <- if (base_model %in% names(level)) colnames(level[[base_model]]) else NULL
          } else {
            always_vars <- NULL
          }
        }
        
        # Execute rolling window
        out <- runRollingWindow_rf(
          model_data = model_data,
          train_size = train_size,
          time_index = time_index,
          n_obs = n_obs,
          always_split_vars = always_vars
        )
        
        # Store results directly with model name as key
        results_rf[[model_name]] <- out
      }
      
      ############# Carregar bases ln_RV #############
      
      
      
      ln <- list(
        # Regressores first
        # ln_regressores_HAR    = ln_regressores_HAR,
        # ln_topics  = ln_topics,
        # ln_topics_IV = ln_topics_IV,
        # ln_IV      = ln_IV,
        
        # Remaining variables
        ln_HAR    = ln_HAR,
        ln_HARCJ  = ln_HARCJ,
        ln_LHARCJ = ln_LHARCJ,
        ln_HARQ_1 = ln_HARQ_1,
        ln_SHAR   = ln_SHAR
      )
      
      train_size <- sum(index(ln_rv_var) <= as.POSIXct("2020-12-31 23:59", format = "%Y-%m-%d %H:%M"))
      
      ln_train_rv_var <- ln_rv_var[1:train_size, ]
      ln_test_rv_var  <- ln_rv_var[(train_size + 1):nrow(ln_rv_var), ]
      
      gc()
      
      target_variable    <- ln_rv_var
      # 2a. If you know which column you want to rename (e.g. the first column):
      colnames(target_variable)[1] <- "rv_var"
      realized_variable <- ln_test_rv_var
      
      # Precompute constant values outside the parallel loop
      n_obs     <- nrow(target_variable)
      time_index <- index(target_variable[(train_size + 1):n_obs])
      
      ############# Regularização em ln ############################
      
      ln_results <- list()
      for(model_name in names(ln)) {
        model_data <- ln[[model_name]]
        out <- runRollingWindow(
          model_data = model_data,
          train_size = train_size,
          time_index = time_index,
          n_obs = n_obs
        )
        ln_results[[model_name]] <- out
      }
      
      ln_nonzero_coefs_lasso_results    <- do.call(cbind, lapply(ln_results, `[[`, "nonzero_coefs_lasso"))
      ln_nonzero_coefs_adalasso_results <- do.call(cbind, lapply(ln_results, `[[`, "nonzero_coefs_adalasso"))
      gc()
      
      
      
      
      ############# Random Forest em ln ##################
      ln <- list(
        # Regressores first
        ln_regressores_HAR    = ln_regressores_HAR,
        ln_topics  = ln_topics,
        ln_topics_IV = ln_topics_IV,
        ln_IV      = ln_IV,
        
        # Remaining variables
        ln_HAR    = ln_HAR,
        ln_HARCJ  = ln_HARCJ,
        ln_LHARCJ = ln_LHARCJ,
        ln_HARQ_1 = ln_HARQ_1,
        ln_SHAR   = ln_SHAR
      )
      
      # Initialize list to store results
      ln_results_rf <- list()
      
      # Loop through each model sequentially
      for (model_name in names(ln)) {
        model_data <- ln[[model_name]]
        
        # First check if model_name ends with _IV
        if (grepl("s_IV$", model_name)) {
          always_vars <- c("IVAR_1","IVAR_5","IVAR_21")
        } else {
          # Determine base model for always.split.variables
          model_suffixes <- c("HAR", "HARCJ", "LHARCJ", "HARQ_1", "SHAR")
          pattern <- paste0("(_ln|s)_(", paste(model_suffixes, collapse = "|"), ")$")
          
          if (grepl(pattern, model_name)) {
            base_model <- regmatches(model_name, regexpr(pattern, model_name))
            base_model <- gsub(pattern, "ln_\\2", base_model)
            
            if (base_model %in% names(ln)) {
              always_vars <- c(colnames(ln[[base_model]]))
            } else {
              always_vars <- NULL
            }
          } else {
            always_vars <- NULL
          }
        }
        
        # Execute rolling window
        out <- runRollingWindow_rf(
          model_data = model_data,
          train_size = train_size,
          time_index = time_index,
          n_obs = n_obs,
          always_split_vars = always_vars
        )
        
        # Store results directly in list with model name as key
        ln_results_rf[[model_name]] <- out
      }
      ############# Carregar bases sqrt_RV #############
      
      
      
      # Agrupar conjuntos de dados em lista única
      sqrt <- list(
        # sqrt_regressores_HAR      = sqrt_regressores_HAR,
        # sqrt_topics    = sqrt_topics,
        # sqrt_topics_IV = sqrt_topics_IV,
        sqrt_IV        = sqrt_IV,
        sqrt_HAR       = sqrt_HAR,
        sqrt_HARCJ     = sqrt_HARCJ,
        sqrt_LHARCJ    = sqrt_LHARCJ,
        sqrt_HARQ_1    = sqrt_HARQ_1,
        sqrt_SHAR      = sqrt_SHAR
      )
      
      # Definir tamanho de treinamento
      train_size <- sum(index(sqrt_rv_var) <= as.POSIXct("2020-12-31 23:59", format = "%Y-%m-%d %H:%M"))
      
      # Dividir em treino e teste
      sqrt_train_rv_var <- sqrt_rv_var[1:train_size, ]
      sqrt_test_rv_var  <- sqrt_rv_var[(train_size + 1):nrow(sqrt_rv_var), ]
      
      gc()
      
      target_variable    <- sqrt_rv_var
      # 2a. If you know which column you want to rename (e.g. the first column):
      colnames(target_variable)[1] <- "rv_var"
      realized_variable  <- sqrt_test_rv_var
      
      # Pré-computar constantes
      n_obs      <- nrow(target_variable)
      time_index <- index(target_variable[(train_size + 1):n_obs])
      
      ############# Regularização em sqrt #############
      
      sqrt_results <- list()
      for(model_name in names(sqrt)) {
        model_data <- sqrt[[model_name]]
        out <- runRollingWindow(
          model_data = model_data,
          train_size = train_size,
          time_index = time_index,
          n_obs = n_obs
        )
        sqrt_results[[model_name]] <- out
      }
      
      sqrt_nonzero_coefs_lasso_results    <- do.call(cbind, lapply(sqrt_results, `[[`, "nonzero_coefs_lasso"))
      sqrt_nonzero_coefs_adalasso_results <- do.call(cbind, lapply(sqrt_results, `[[`, "nonzero_coefs_adalasso"))
      gc()
      
      
      ############# Random Forest em sqrt #############
      sqrt <- list(
        sqrt_regressores_HAR      = sqrt_regressores_HAR,
        sqrt_topics    = sqrt_topics,
        sqrt_topics_IV = sqrt_topics_IV,
        sqrt_IV        = sqrt_IV,
        sqrt_HAR       = sqrt_HAR,
        sqrt_HARCJ     = sqrt_HARCJ,
        sqrt_LHARCJ    = sqrt_LHARCJ,
        sqrt_HARQ_1    = sqrt_HARQ_1,
        sqrt_SHAR      = sqrt_SHAR
      )
      
      sqrt_results_rf <- list()
      
      for (model_name in names(sqrt)) {
        model_data <- sqrt[[model_name]]
        
        # First check if model_name ends with _IV
        if (grepl("s_IV$", model_name)) {
          always_vars <- c("IVAR_1","IVAR_5","IVAR_21")
        } else {
          # Determine base model for always.split.variables
          model_suffixes <- c("HAR", "HARCJ", "LHARCJ", "HARQ_1", "SHAR")
          pattern <- paste0("(_sqrt|s)_(", paste(model_suffixes, collapse = "|"), ")$")
          
          if (grepl(pattern, model_name)) {
            base_model <- regmatches(model_name, regexpr(pattern, model_name))
            base_model <- gsub(pattern, "sqrt_\\1", base_model)
            
            if (base_model %in% names(sqrt)) {
              always_vars <- colnames(sqrt[[base_model]])
            } else {
              always_vars <- NULL
            }
          } else {
            always_vars <- NULL
          }
        }
        
        out <- runRollingWindow_rf(
          model_data = model_data,
          train_size = train_size,
          time_index = time_index,
          n_obs = n_obs,
          always_split_vars = always_vars
        )
        
        sqrt_results_rf[[model_name]] <- out
      }
      ######################  consolidar previsões #############
      # Map each transform name to its two lists (OLS/WLS) and RF list
      transforms <- list(
        level = list(base = results,      rf = results_rf),
        ln    = list(base = ln_results,   rf = ln_results_rf),
        sqrt  = list(base = sqrt_results, rf = sqrt_results_rf)
      )
      
      metrics <- c("predictions")
      all_results <- list()
      
      for (trans in names(transforms)) {
        base_list <- transforms[[trans]]$base
        rf_list   <- transforms[[trans]]$rf
        
        # for each metric, build and merge
        m_list <- list()
        for (m in metrics) {
          # collect all columns for OLS/WLS and RF
          ols <- do.call(cbind, lapply(base_list,   `[[`, paste0(m, "_ols")))
          wls <- do.call(cbind, lapply(base_list,   `[[`, paste0(m, "_wls")))
          rf  <- do.call(cbind, lapply(rf_list,     `[[`, paste0(m, "_rf")))
          
          # name the columns with the source + method
          colnames(ols) <- paste0(names(base_list), "_ols")
          colnames(wls) <- paste0(names(base_list), "_wls")
          colnames(rf)  <- paste0(names(rf_list),   "_rf")
          
          # merge into one xts
          m_list[[m]] <- merge.xts(ols, wls, rf)
        }
        
        all_results[[trans]] <- m_list
        gc()
      }
      
      # You now have:
      # all_results$level$predictions   — the `xts` for level-scale predictions
      # all_results$ln$predictions      — the `xts` for log-scale predictions
      # all_results$sqrt$predictions    — the `xts` for sqrt-scale predictions
      ############### salvar novos arquivos\############
      
      
      end_time <-Sys.time()
      print(end_time - start_time)
      
      out_file <- file.path(base_dir, tkr, "RData_TR", paste0("MCS_", tkr, "_", horizon, ".RData"))
      objs <- setdiff(ls(envir = globalenv()), c("base_dir", "forecast_horizon", "tickers",
                                                 "tkr", "horizon",
                                                 "runRollingWindow_rf",
                                                 "runRollingWindow"))
      
      
      # Save objects
      save(
        list = objs,
        file = out_file
      )
      message("Saved objects to: ", basename(out_file))
      
      # Remove the actual objects from loop_env (if needed)
      rm(list = objs)
      gc(full = TRUE, verbose = FALSE)
  }
}





library(xtable)
library(readxl)
library(xts)
library(data.table)
library(glmnet)
library(zoo)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(stringr)

# Vector of tickers_2_2 to process
tickers_2 <- c("BBDC4", "CSNA3", "GGBR4",
               # IBOV_BS",
               "BOVA11",
               "ITUB4", "PETR4")

forecast_horizon_2 <-c("daily", "lead_5", "lead_10", "lead_21")

# Base path up to each ticker’s folder
base_dir_2 <- "~/FEA_USP/Mestrado/Novos/Tese/R/Correto_sqrt_ln/HAR_and_HIV_BASE_NOVA_HARQ/Impurity"


for (h_2 in forecast_horizon_2) {
  
  # Determine k based on h
  k_2 <- switch(h_2,
              "daily" = 1,
              "lead_5" = 5,
              "lead_10" = 10,
              "lead_21" = 21)


for (tkr in tickers_2) {
  # 1. Locate and load
  in_file <- file.path(base_dir_2, tkr, "RData_TR", paste0("MCS_", tkr, "_", h_2, ".RData"))
  if (!file.exists(in_file)) {
    warning("File not found, skipping: ", in_file); next
  }
  loaded_names <- load(in_file)
  message("Loaded from ", tkr, ": ", paste(loaded_names, collapse = ", "))
  
  # 2. Copy all “MCS…” objects unchanged, suffixing with _<ticker>
  mcs_objs <- grep("MCS", loaded_names, value = TRUE)
  for (nm in mcs_objs) {
    new_nm <- paste0(nm, "_", tkr)
    assign(new_nm, get(nm), envir = .GlobalEnv)
    message("  • Copied MCS object: ", new_nm)
  }
  
  # 3. For each “results…” object with specific suffixes, compute column‐means and save only that
  # pattern <- "^(QLIKE|SE|AE|PAE|HSE)(?=.*results)"
  # res_objs <- grep(pattern, loaded_names, value = TRUE, ignore.case = TRUE)
  
  
  hits <- grep("^(QLIKE|SE|AE|PAE|HSE)",
               loaded_names, value = TRUE, ignore.case = TRUE, perl = TRUE)
  
  # 2) Remove anything that has 'topics' in it (case-insensitive)
  res_objs <- hits[!grepl("results", hits, ignore.case = TRUE)]
  
  
  for (nm in res_objs) {
    obj <- get(nm, envir = .GlobalEnv)
    if (is.data.frame(obj) || is.matrix(obj)) {
      cm <- colMeans(obj, na.rm = TRUE)
      
      # Identify HAR_ols reference column (excluding SHAR)
      tmp_idx <- grep("HAR_ols", names(cm), ignore.case = TRUE)
      har_idx <- tmp_idx[!grepl("SHAR|regressores", names(cm)[tmp_idx], ignore.case = TRUE)]
      
      if (length(har_idx) != 1) {
        warning("Expected exactly one HAR_ols (no SHAR) in ", nm,
                "; found ", length(har_idx), ". Skipping.")
        next
      }
      
      # Normalize metrics relative to HAR_ols
      cm <- cm / cm[har_idx]
      
      # Create new normalized object
      cm_nm <- paste0(nm, "_", tkr)
      assign(cm_nm, cm, envir = .GlobalEnv)
      message("  • Created normalized col‐mean object: ", cm_nm)
    } else {
      warning("Not a data.frame/matrix, skipping colMeans for: ", nm)
    }
  }
  
  # Clean up names by removing "results_" prefix
  objs_to_rename <- grep(paste0("results.*_", tkr, "$"), ls(.GlobalEnv), value = TRUE)
  
  
  # for (old_name in objs_to_rename) {
  #   new_name <- sub("results_", "", old_name)
  #   new_name <- sub("BOVA11", "BOVA11", new_name)
  #   if (exists(new_name, envir = .GlobalEnv)) {
  #     warning("Object ", new_name, " already exists. Skipping rename.")
  #     next
  #   }
  #   assign(new_name, get(old_name, envir = .GlobalEnv))
  #   rm(list = old_name, envir = .GlobalEnv)
  #   message("Renamed: ", old_name, " → ", new_name)
  # }
  
  # List all objects in the global environment
  all_objects <- ls(envir = .GlobalEnv)
  
  # Identify objects containing both "MCS" and "BOVA11"
  # target_objects <- all_objects[
  #   grepl("MCS", all_objects) & 
  #     grepl("BOVA11", all_objects)
  # ]
  
  # Rename each target object by replacing "BOVA11" with "BOVA11"
  # for (obj_name in target_objects) {
  #   new_name <- gsub("BOVA11", "BOVA11", obj_name)
  #   assign(new_name, get(obj_name, envir = .GlobalEnv), envir = .GlobalEnv)
  #   rm(list = obj_name, envir = .GlobalEnv)
  # }
  # 
  # 4. Clean up originals
  rm(list = loaded_names, envir = .GlobalEnv)
}


# --- PART 2: Create metric dataframes (FIXED) ---
tickers<- c("BBDC4", "CSNA3", "GGBR4","BOVA11","ITUB4", "PETR4")
all_objs <- ls()
metrics <- c("QLIKE_regressores_HAR","QLIKE_TopicsIV","QLIKE_Topics","QLIKE_IV","QLIKE",
             "SE_regressores_HAR","SE_TopicsIV","SE_Topics","SE_IV","SE",
             "AE_regressores_HAR","AE_TopicsIV","AE_Topics","AE_IV","AE",
             "PAE_regressores_HAR","PAE_TopicsIV","PAE_Topics","PAE_IV","PAE",
             "HSE_regressores_HAR","HSE_TopicsIV","HSE_Topics","HSE_IV","HSE",
             "sqrt_SE_regressores_HAR", "sqrt_SE_TopicsIV", "sqrt_SE_Topics", "sqrt_SE_IV", "sqrt_SE",
             "sqrt_AE_regressores_HAR", "sqrt_AE_TopicsIV", "sqrt_AE_Topics", "sqrt_AE_IV", "sqrt_AE",
             "ln_SE_regressores_HAR",   "ln_SE_TopicsIV",   "ln_SE_Topics",   "ln_SE_IV",   "ln_SE",
             "ln_AE_regressores_HAR",   "ln_AE_TopicsIV",   "ln_AE_Topics",   "ln_AE_IV",   "ln_AE"
)

df_list <- list()

for (obj_name in all_objs) {
  # Check each metric to find a valid prefix match
  found_metric <- NULL
  found_ticker <- NULL
  for (m in metrics) {
    # Check if the object name starts with the metric followed by an underscore
    prefix <- paste0(m, "_")
    if (startsWith(obj_name, prefix)) {
      # Extract the part after the metric prefix
      potential_rest <- sub(prefix, "", obj_name)
      # Split into parts by underscores
      parts <- unlist(strsplit(potential_rest, "_"))
      if (length(parts) >= 1) {
        # The last part is the potential ticker
        possible_ticker <- parts[length(parts)]
        if (possible_ticker %in% tickers) {
          found_metric <- m
          found_ticker <- possible_ticker
          break
        }
      }
    }
  }
  if (is.null(found_metric)) next  # Skip if no valid metric-ticker pair found
  
  metric_part <- found_metric
  tkr_part <- found_ticker
  
  metric_obj <- get(obj_name)
  
  if (isS4(metric_obj)) {
    vals <- tryCatch(as.numeric(metric_obj), error = function(e) numeric(0))
    nms <- tryCatch(names(metric_obj), error = function(e) character(0))
  } else {
    vals <- unname(metric_obj)
    nms <- names(metric_obj)
  }
  
  if (length(vals) > 0 && length(nms) > 0) {
    df_list[[obj_name]] <- data.frame(
      Model = nms,
      Value = vals,
      Metric = metric_part,
      Ticker = tkr_part,
      stringsAsFactors = FALSE
    )
  }
}

# Combine all dataframes into long format
all_data <- bind_rows(df_list)

# Split into individual dataframes by metric
metric_dfs <- split(all_data, all_data$Metric)

# --- PART 3: Create final dataframes with coloring and column ordering ---

# Define desired column order (excluding "Model")
column_order <- c("BOVA11", "BBDC4", "CSNA3", "GGBR4", "ITUB4", "PETR4")

# Loop through each metric dataframe and process
for (metric_name in names(metric_dfs)) {
  # Ensure the metric dataframe exists and has data
  df_metric <- metric_dfs[[metric_name]]
  if (is.null(df_metric) || nrow(df_metric) == 0) next
  
  # Pivot to wide format, handle duplicates by taking the first occurrence
  df_wide <- df_metric %>%
    select(-Metric) %>%
    pivot_wider(
      names_from = Ticker,
      values_from = Value,
      values_fn = list(Value = first)  # Handle duplicates
    )
  
  # Check if all required columns exist; if not, create them with NA
  missing_cols <- setdiff(column_order, names(df_wide))
  for (col in missing_cols) {
    df_wide[[col]] <- NA_real_
  }
  
  # Select and order columns, then format values
  df <- df_wide %>%
    select(Model, all_of(column_order)) %>%
    mutate(across(-Model, ~ {
      ifelse(is.na(.x), 
             "-", 
             sprintf("%.3f", .x))  # Format non-NA to 3 decimals
    }))
  
  # Apply cell coloring using ORIGINAL model names
  for (ticker_col in names(df)[-1]) {
    
    # Build mcs_obj_name based on metric_name prefix
    if (startsWith(metric_name, "sqrt_")) {
      # remove the leading "sqrt_"
      metric_base <- sub("^sqrt_", "", metric_name)
      
      # now build the object name with a single "sqrt_"
      mcs_obj_name <- paste0(
        "sqrt_",
        "MCS_",
        metric_base,
        "_",
        ticker_col
      )
    }
    else if (startsWith(metric_name, "ln_")) {
      mcs_obj_name <- paste0(
        "ln_",
        "MCS_",
        sub("^ln_", "", metric_name),
        "_",
        ticker_col
      )
    } else {
      mcs_obj_name <- paste0(
        "MCS_",
        metric_name,
        "_",
        ticker_col
      )
    }
    if (exists(mcs_obj_name)) {
      mcs_obj <- get(mcs_obj_name)
      mcs_models <- mcs_obj@Info$model.names
      bold_rows <- df$Model %in% mcs_models
      
      df[[ticker_col]] <- ifelse(
        bold_rows,
        paste0("\\cellcolor{gray!25}{", df[[ticker_col]], "}"),
        df[[ticker_col]]
      )
    }
  }
  
  # Rename Model column with corrected substitutions
  df <- df %>%
    mutate(Model = Model %>%
             str_remove_all('^(ln_|sqrt_)') %>%
             str_replace_all('regressores_HAR', 'HARX') %>%
             str_replace_all('topics_IV', 'NEWS IV') %>%
             str_replace_all('(^|_)topics($|_)', '\\1NEWS\\2') %>%
             # str_replace_all('HARQ_1', 'HARQ') %>%
             str_replace_all('_ols$', ' (OLS)') %>%
             str_replace_all('_wls$', ' (WLS)') %>%
             str_replace_all('_rf$', ' (RF)') %>%
             str_replace_all('_BG$',  ' (BG)')
    )
  
  # Assign processed df back to environment
  assign(paste0(metric_name, '_df'), df)
}

generate_custom_table <- function(df, metric) {
  # 1) Identify row indices for each category
  ols_indices <- grep("\\(OLS\\)", df[[1]])
  wls_indices <- grep("\\(WLS\\)", df[[1]])
  rf_indices  <- grep("^(HARX \\(RF\\)|NEWS \\(RF\\)|NEWS IV \\(RF\\))$", df[[1]])
  bg_indices  <- grep("\\(BG\\)", df[[1]])
  
  # Create a vector of all categorized indices to find uncategorized ones
  all_categorized_indices <- c(ols_indices, wls_indices, rf_indices, bg_indices)
  all_row_indices <- 1:nrow(df)
  other_indices <- setdiff(all_row_indices, all_categorized_indices) # Rows not in OLS, WLS, RF, or BG
  
  # 2) Reorder the data frame
  # Start with OLS, then WLS, then RF, then BG, then any other rows
  ordered_df <- df[c(ols_indices, wls_indices, rf_indices, bg_indices, other_indices), ]
  
  # 3) Recalculate the 'last' row indices based on the *newly ordered* data frame
  # These are now relative to the 'ordered_df'
  current_row_count <- 0
  
  last_ols <- if (length(ols_indices) > 0) {
    current_row_count <- current_row_count + length(ols_indices)
    current_row_count
  } else {
    NULL
  }
  
  last_wls <- if (length(wls_indices) > 0) {
    current_row_count <- current_row_count + length(wls_indices)
    current_row_count
  } else {
    NULL
  }
  
  last_rf <- if (length(rf_indices) > 0) {
    current_row_count <- current_row_count + length(rf_indices)
    current_row_count
  } else {
    NULL
  }
  
  last_bg <- if (length(bg_indices) > 0) {
    # Only add linespace if BG rows are not the absolute last rows in the table
    # (i.e., if there are 'other_indices' rows following them)
    if (length(other_indices) > 0) {
      current_row_count <- current_row_count + length(bg_indices)
      current_row_count
    } else {
      # If BG rows are the last, we don't need linespace after them,
      # but we still need to know their position for other logic if any.
      # However, for addlinespace, we set it to NULL.
      NULL # Or handle as per specific needs if BG is truly last.
      # For addlinespace, setting to NULL means no line will be added.
    }
  } else {
    NULL
  }
  
  
  # 4) Build the kable and styling, using the 'ordered_df'
  #    Add a LaTeX label based on metric, and enable threeparttable for footnotes:
  tbl <- kable(
    ordered_df, # Use the reordered data frame
    format    = "latex",
    booktabs  = TRUE,
    linesep   = "",              # disable automatic \addlinespace everywhere
    align     = "lcccccc",
    col.names = c(
      "",
      "\\textbf{BOVA11}",
      "\\textbf{BBDC4}",
      "\\textbf{CSNA3}",
      "\\textbf{GGBR4}",
      "\\textbf{ITUB4}",
      "\\textbf{PETR4}"
    ),
    caption   = paste0(metric, " results for h=",k_2),
    label     = paste0(metric, " ",h_2),
    escape    = FALSE
  ) %>%
    kable_styling(
      latex_options = c("hold_position", "threeparttable"),
      full_width    = FALSE
    ) %>%
    row_spec(0, bold = TRUE)      # header row bold
  
  # 5) Add \addlinespace after Last OLS, WLS, RF, and BG rows if found
  #    These are now based on the new counts in the ordered_df
  if (!is.null(last_ols) && last_ols < nrow(ordered_df)) { # Check if not the last row
    tbl <- tbl %>% row_spec(last_ols, extra_latex_after = "\\addlinespace[2em]")
  }
  if (!is.null(last_wls) && last_wls < nrow(ordered_df)) { # Check if not the last row
    tbl <- tbl %>% row_spec(last_wls, extra_latex_after = "\\addlinespace[2em]")
  }
  if (!is.null(last_rf) && last_rf < nrow(ordered_df)) { # Check if not the last row
    tbl <- tbl %>% row_spec(last_rf, extra_latex_after = "\\addlinespace[2em]")
  }
  # For last_bg, the logic in step 3 already considers if it's followed by 'other' rows.
  # If last_bg was set to a row number, it means there are rows after it (other_indices).
  if (!is.null(last_bg) && last_bg < nrow(ordered_df)) { # Ensure it's not the absolute last row
    tbl <- tbl %>% row_spec(last_bg, extra_latex_after = "\\addlinespace[2em]")
  }
  
  # 6) Add the tablenote via a threeparttable footnote
  tbl <- tbl %>%
    footnote(
      general = "\\textit{Note:} This table shows the loss ratios of various models compared to the HAR estimated through OLS. Cells highlighted indicate models that are part of the MCS at a 90\\% confidence level. Cells with missing values pertain to models that yielded forecasts with negative predictions",
      general_title = "",          # suppress “Note:” prefix if you like
      escape = FALSE,
      threeparttable = TRUE
    )
  
  return(tbl)
}



## R Script: Generate LaTeX Tables for All Metrics


setwd(file.path(base_dir_2, paste0("Tabelas_MCS_k_", k_2)))

for (metric in metrics) {
  # 1) build the data‐frame name
  df_name <- paste0(metric, "_df")
  if (!exists(df_name)) {
    warning(sprintf("Data frame '%s' not found. Skipping metric: %s", df_name, metric))
    next
  }
  df <- get(df_name)
  
  # 2) apply all your renaming rules in sequence
  metric_label <- metric %>%
    # HAR and topics first
    str_replace_all("regressores_HAR", "HARX") %>%
    str_replace_all("TopicsIV",      "NEWS IV") %>%
    str_replace_all("(^|_)Topics($|_)", "\\1NEWS\\2") %>%
    # MSE group: longest first
    str_replace_all("^ln_SE",    "MSE-LOG ") %>%
    str_replace_all("^sqrt_SE",  "MSE-SD ") %>%
    str_replace_all("^HSE",      "HMSE ") %>%
    str_replace_all("^SE",       "MSE ") %>%
    # MAE group: longest first
    str_replace_all("^ln_AE",     "MAE-LOG ") %>%
    str_replace_all("^sqrt_AE",   "MAE-SD ") %>%
    str_replace_all("^PAE",       "MAPE ") %>%
    str_replace_all("^AE",        "MAE ") %>%
    str_replace_all("^QLIKE",        "QLIKE ") %>%
    # finally, remove all hyphens
    str_replace_all("_", "")
  
  # 3) generate LaTeX using the cleaned‐up label
  latex_code <- generate_custom_table(df, metric_label)
  assign(paste0(metric, "_latex"), latex_code, envir = .GlobalEnv)
  
  # 4) write out the file, using the transformed name if you like
  out_file <- paste0(metric_label, ".tex")
  cat(latex_code, file = out_file)
  message(sprintf(
    "Written LaTeX table for '%s' (as '%s') to %s",
    metric, metric_label, out_file
  ))
}






# --- PART 2: Create metric dataframes (FIXED) ---
tickers<- c("BBDC4", "CSNA3", "GGBR4","BOVA11","ITUB4", "PETR4")
all_objs <- ls()
metrics <- c("sqrt_SE", "sqrt_AE")

df_list <- list()

for (obj_name in all_objs) {
  # Check each metric to find a valid prefix match
  found_metric <- NULL
  found_ticker <- NULL
  for (m in metrics) {
    # Check if the object name starts with the metric followed by an underscore
    prefix <- paste0(m, "_")
    if (startsWith(obj_name, prefix)) {
      # Extract the part after the metric prefix
      potential_rest <- sub(prefix, "", obj_name)
      # Split into parts by underscores
      parts <- unlist(strsplit(potential_rest, "_"))
      if (length(parts) >= 1) {
        # The last part is the potential ticker
        possible_ticker <- parts[length(parts)]
        if (possible_ticker %in% tickers) {
          found_metric <- m
          found_ticker <- possible_ticker
          break
        }
      }
    }
  }
  if (is.null(found_metric)) next  # Skip if no valid metric-ticker pair found
  
  metric_part <- found_metric
  tkr_part <- found_ticker
  
  metric_obj <- get(obj_name)
  
  if (isS4(metric_obj)) {
    vals <- tryCatch(as.numeric(metric_obj), error = function(e) numeric(0))
    nms <- tryCatch(names(metric_obj), error = function(e) character(0))
  } else {
    vals <- unname(metric_obj)
    nms <- names(metric_obj)
  }
  
  if (length(vals) > 0 && length(nms) > 0) {
    df_list[[obj_name]] <- data.frame(
      Model = nms,
      Value = vals,
      Metric = metric_part,
      Ticker = tkr_part,
      stringsAsFactors = FALSE
    )
  }
}

# Combine all dataframes into long format
all_data <- bind_rows(df_list)

# Split into individual dataframes by metric
metric_dfs <- split(all_data, all_data$Metric)

# --- PART 3: Create final dataframes with coloring and column ordering ---

# Define desired column order (excluding "Model")
column_order <- c("BOVA11", "BBDC4", "CSNA3", "GGBR4", "ITUB4", "PETR4")

# Loop through each metric dataframe and process
for (metric_name in names(metric_dfs)) {
  # Ensure the metric dataframe exists and has data
  df_metric <- metric_dfs[[metric_name]]
  if (is.null(df_metric) || nrow(df_metric) == 0) next
  
  # Pivot to wide format, handle duplicates by taking the first occurrence
  df_wide <- df_metric %>%
    select(-Metric) %>%
    pivot_wider(
      names_from = Ticker,
      values_from = Value,
      values_fn = list(Value = first)  # Handle duplicates
    )
  
  # Check if all required columns exist; if not, create them with NA
  missing_cols <- setdiff(column_order, names(df_wide))
  for (col in missing_cols) {
    df_wide[[col]] <- NA_real_
  }
  
  # Select and order columns, then format values
  df <- df_wide %>%
    select(Model, all_of(column_order)) %>%
    mutate(across(-Model, ~ {
      ifelse(is.na(.x), 
             "-", 
             sprintf("%.3f", .x))  # Format non-NA to 3 decimals
    }))
  
  # Apply cell coloring using ORIGINAL model names
  for (ticker_col in names(df)[-1]) {
    
    # Build mcs_obj_name based on metric_name prefix
    if (startsWith(metric_name, "sqrt_")) {
      # remove the leading "sqrt_"
      metric_base <- sub("^sqrt_", "", metric_name)
      
      # now build the object name with a single "sqrt_"
      mcs_obj_name <- paste0(
        "sqrt_",
        "MCS_",
        metric_base,
        "_",
        ticker_col
      )
    }
    else if (startsWith(metric_name, "ln_")) {
      mcs_obj_name <- paste0(
        "ln_",
        "MCS_",
        sub("^ln_", "", metric_name),
        "_",
        ticker_col
      )
    } else {
      mcs_obj_name <- paste0(
        "MCS_",
        metric_name,
        "_",
        ticker_col
      )
    }
    if (exists(mcs_obj_name)) {
      mcs_obj <- get(mcs_obj_name)
      mcs_models <- mcs_obj@Info$model.names
      bold_rows <- df$Model %in% mcs_models
      
      df[[ticker_col]] <- ifelse(
        bold_rows,
        paste0("\\cellcolor{gray!25}{", df[[ticker_col]], "}"),
        df[[ticker_col]]
      )
    }
  }
  
  # Rename Model column with corrected substitutions
  df <- df %>%
    mutate(Model = Model %>%
             str_remove_all('^(ln_|sqrt_)') %>%
             str_replace_all('regressores_HAR', 'HARX') %>%
             str_replace_all('topics_IV', 'NEWS IV') %>%
             str_replace_all('(^|_)topics($|_)', '\\1NEWS\\2') %>%
             # str_replace_all('HARQ_1', 'HARQ') %>%
             str_replace_all('_ols$', ' (OLS)') %>%
             str_replace_all('_wls$', ' (WLS)') %>%
             str_replace_all('_BG$',  ' (RF)')
    )
  
  # Assign processed df back to environment
  assign(paste0(metric_name, '_df'), df)
}



## R Script: Generate LaTeX Tables for All Metrics

setwd(file.path(base_dir_2, paste0("Tabelas_MCS_k_", k_2)))

for (metric in metrics) {
  # 1) build the data‐frame name
  df_name <- paste0(metric, "_df")
  if (!exists(df_name)) {
    warning(sprintf("Data frame '%s' not found. Skipping metric: %s", df_name, metric))
    next
  }
  df <- get(df_name)
  
  # 2) apply all your renaming rules in sequence
  metric_label <- metric %>%
    # HAR and topics first
    str_replace_all("regressores_HAR", "HARX") %>%
    str_replace_all("Topics_IV",      "NEWS IV") %>%
    str_replace_all("(^|_)Topics($|_)", "\\1NEWS\\2") %>%
    # MSE group: longest first
    str_replace_all("^ln_SE",    "MSE-LOG ") %>%
    str_replace_all("^sqrt_SE",  "MSE-SD ") %>%
    str_replace_all("^HSE",      "HMSE ") %>%
    str_replace_all("^SE",       "MSE ") %>%
    # MAE group: longest first
    str_replace_all("^ln_AE",     "MAE-LOG ") %>%
    str_replace_all("^sqrt_AE",   "MAE-SD ") %>%
    str_replace_all("^PAE",       "MAPE ") %>%
    str_replace_all("^AE",        "MAE ") %>%
    # finally, remove all hyphens
    str_replace_all("_", "")
  
  # 3) generate LaTeX using the cleaned‐up label
  latex_code <- generate_custom_table(df, metric_label)
  assign(paste0(metric, "_latex"), latex_code, envir = .GlobalEnv)
  
  # 4) write out the file, using the transformed name if you like
  out_file <- paste0(metric_label, ".tex")
  cat(latex_code, file = out_file)
  message(sprintf(
    "Written LaTeX table for '%s' (as '%s') to %s",
    metric, metric_label, out_file
  ))
}

rm(list=setdiff(ls(envir = .GlobalEnv, all.names = TRUE), c("tickers_2","tkr",
                                                    "forecast_horizon_2","k_2","h_2",
                                                    "base_dir_2")))
                                                    
}





